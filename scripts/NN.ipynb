{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mingchen/Course/CS235/CS235Project/scripts\n"
     ]
    }
   ],
   "source": [
    "datapath='../../features'\n",
    "Flods=[0,1,2,3]\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import keras\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self, input_shape, num_classes, x_train, y_train,x_test,y_test):\n",
    "\n",
    "        self.model = Sequential()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.x_train = x_train\n",
    "        self.x_test=x_test\n",
    "        self.y_train = []\n",
    "        self.y_test=[]\n",
    "        self.y_clean=[]\n",
    "        for i in range(0, len(y_train)):\n",
    "            self.y_train.append(y_train[i])\n",
    "            self.y_clean.append(y_train[i])\n",
    "        for i in range(0,len(y_test)):\n",
    "            self.y_test.append(y_test[i])\n",
    "\n",
    "        #self.y_train = keras.utils.to_categorical(self.y_train, self.num_classes)\n",
    "        #self.y_test = keras.utils.to_categorical(self.y_test, self.num_classes)\n",
    "        # self.y_clean = keras.utils.to_categorical(self.y_clean, self.num_classes)\n",
    "\n",
    "        self.y_test=np.array(self.y_test)\n",
    "        self.y_train=np.array(self.y_train)\n",
    "        self.y_clean=np.array(self.y_clean)\n",
    "\n",
    "        k=128\n",
    "        self.model.add(Dense(k,activation='relu',input_shape=input_shape,\n",
    "                             #kernel_initializer='he_normal',\n",
    "                              kernel_initializer=keras.initializers.RandomNormal(0,0.001)))\n",
    "        # self.model.add(Dense(k, activation='relu', input_shape=input_shape\n",
    "        #                      , kernel_initializer=keras.initializers.RandomNormal(0, 1.0)))\n",
    "        #self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(k/2,activation='relu',\n",
    "                             kernel_initializer='he_normal'))\n",
    "        #self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(num_classes,activation='relu',\n",
    "                             #kernel_initializer='he_normal'))\n",
    "                             kernel_initializer=keras.initializers.RandomNormal(0,0.001/float(k))))\n",
    "        #self.model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#         self.model.compile(loss='categorical_crossentropy',\n",
    "#                            optimizer=optimizers.Adadelta(), metrics=[\"accuracy\"])\n",
    "        self.model.compile(loss='mean_squared_error',\n",
    "                           optimizer=optimizers.Adadelta(), metrics=[\"accuracy\"])\n",
    "        #print self.model.summary()\n",
    "\n",
    "    def set_weights(self, weight):\n",
    "        self.model.set_weights(weight)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, batch_size, epochs,verbose=1,callbacks=[]):\n",
    "        self.model.fit(\n",
    "            self.x_train, self.y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(self.x_test,self.y_test),\n",
    "            shuffle=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import numpy as np\n",
    "class History(callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_acc=[]\n",
    "        self.train_loss=[]\n",
    "        self.test_acc=[]\n",
    "        self.test_loss=[]\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.test_acc.append(logs.get('val_acc'))\n",
    "        self.test_loss.append(logs.get('val_loss'))\n",
    "    def on_train_end(self,logs={}):\n",
    "        np.save('../result/train_acc',self.train_acc)\n",
    "        np.save('../result/train_loss',self.train_loss)\n",
    "        np.save('../result/test_acc',self.test_acc)\n",
    "        np.save('../result/test_loss',self.test_loss)\n",
    "        plt.cla()\n",
    "        plt.plot(self.train_acc,'r',linewidth=2)\n",
    "        plt.plot(self.test_acc,'b',linewidth=2)\n",
    "        plt.legend(['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((18000, 55), (18000,))\n",
      "((6000, 55), (6000,))\n",
      "Train on 18000 samples, validate on 6000 samples\n",
      "Epoch 1/200\n",
      "18000/18000 [==============================] - 2s 110us/step - loss: 0.1619 - acc: 0.7956 - val_loss: 0.1176 - val_acc: 0.8483\n",
      "Epoch 2/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1351 - acc: 0.8204 - val_loss: 0.1274 - val_acc: 0.8357\n",
      "Epoch 3/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1243 - acc: 0.8404 - val_loss: 0.1225 - val_acc: 0.8560\n",
      "Epoch 4/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1179 - acc: 0.8542 - val_loss: 0.1054 - val_acc: 0.8690\n",
      "Epoch 5/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1125 - acc: 0.8633 - val_loss: 0.1109 - val_acc: 0.8745\n",
      "Epoch 6/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1101 - acc: 0.8673 - val_loss: 0.1044 - val_acc: 0.8732\n",
      "Epoch 7/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1096 - acc: 0.8694 - val_loss: 0.0944 - val_acc: 0.8813\n",
      "Epoch 8/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1060 - acc: 0.8742 - val_loss: 0.1013 - val_acc: 0.8715\n",
      "Epoch 9/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1071 - acc: 0.8735 - val_loss: 0.1138 - val_acc: 0.8815\n",
      "Epoch 10/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1029 - acc: 0.8773 - val_loss: 0.1049 - val_acc: 0.8862\n",
      "Epoch 11/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1043 - acc: 0.8758 - val_loss: 0.0972 - val_acc: 0.8835\n",
      "Epoch 12/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1040 - acc: 0.8765 - val_loss: 0.1001 - val_acc: 0.8857\n",
      "Epoch 13/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1022 - acc: 0.8784 - val_loss: 0.1028 - val_acc: 0.8753\n",
      "Epoch 14/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.1010 - acc: 0.8796 - val_loss: 0.0999 - val_acc: 0.8870\n",
      "Epoch 15/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.1007 - acc: 0.8801 - val_loss: 0.0979 - val_acc: 0.8843\n",
      "Epoch 16/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0995 - acc: 0.8833 - val_loss: 0.0916 - val_acc: 0.8935\n",
      "Epoch 17/200\n",
      "18000/18000 [==============================] - 1s 30us/step - loss: 0.0998 - acc: 0.8808 - val_loss: 0.0936 - val_acc: 0.8938\n",
      "Epoch 18/200\n",
      "18000/18000 [==============================] - 1s 30us/step - loss: 0.0985 - acc: 0.8822 - val_loss: 0.0929 - val_acc: 0.8863\n",
      "Epoch 19/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0979 - acc: 0.8838 - val_loss: 0.0932 - val_acc: 0.8937\n",
      "Epoch 20/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0976 - acc: 0.8847 - val_loss: 0.0921 - val_acc: 0.8927\n",
      "Epoch 21/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.0977 - acc: 0.8869 - val_loss: 0.0885 - val_acc: 0.9000\n",
      "Epoch 22/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0969 - acc: 0.8854 - val_loss: 0.1105 - val_acc: 0.8843\n",
      "Epoch 23/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0971 - acc: 0.8832 - val_loss: 0.0902 - val_acc: 0.8985\n",
      "Epoch 24/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.0991 - acc: 0.8812 - val_loss: 0.1106 - val_acc: 0.8922\n",
      "Epoch 25/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.0964 - acc: 0.8863 - val_loss: 0.0875 - val_acc: 0.8890\n",
      "Epoch 26/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0961 - acc: 0.8844 - val_loss: 0.1031 - val_acc: 0.8910\n",
      "Epoch 27/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0960 - acc: 0.8856 - val_loss: 0.0966 - val_acc: 0.8925\n",
      "Epoch 28/200\n",
      "18000/18000 [==============================] - 1s 30us/step - loss: 0.0953 - acc: 0.8861 - val_loss: 0.0870 - val_acc: 0.8955\n",
      "Epoch 29/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0969 - acc: 0.8844 - val_loss: 0.0870 - val_acc: 0.8942\n",
      "Epoch 30/200\n",
      "18000/18000 [==============================] - 0s 28us/step - loss: 0.0962 - acc: 0.8877 - val_loss: 0.0919 - val_acc: 0.8945\n",
      "Epoch 31/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.0964 - acc: 0.8862 - val_loss: 0.0967 - val_acc: 0.8942\n",
      "Epoch 32/200\n",
      "18000/18000 [==============================] - 1s 28us/step - loss: 0.0951 - acc: 0.8868 - val_loss: 0.0913 - val_acc: 0.8938\n",
      "Epoch 33/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0955 - acc: 0.8876 - val_loss: 0.0940 - val_acc: 0.8925\n",
      "Epoch 34/200\n",
      "18000/18000 [==============================] - 1s 29us/step - loss: 0.0958 - acc: 0.8872 - val_loss: 0.0890 - val_acc: 0.8940\n",
      "Epoch 35/200\n",
      "  128/18000 [..............................] - ETA: 0s - loss: 0.1299 - acc: 0.8281"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-3444dba118db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#print(net.model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexsY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#     err=np.sum(testY[:,0]*ans<=0)/testY.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-767524f3908e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batch_size, epochs, verbose, callbacks)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         )\n",
      "\u001b[0;32m/home/mingchen/Research/.venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/mingchen/Research/.venv/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mingchen/Research/.venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mingchen/Research/.venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mingchen/Research/.venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epoch=200\n",
    "num_classes=1\n",
    "for flod in Flods:\n",
    "    trainfile=open('{0}/cv_{1}_4_{2}_4/cv_train_features_{1}_4_{2}_4.csv'.format(datapath,flod,flod+1))\n",
    "    testfile=open('{0}/cv_{1}_4_{2}_4/cv_test_features_{1}_4_{2}_4.csv'.format(datapath,flod,flod+1))\n",
    "    trainX=[]\n",
    "    trainY=[]\n",
    "    testX=[]\n",
    "    testY=[]\n",
    "    for line in trainfile:\n",
    "        line=line.split(',')[1:]\n",
    "        if line[0]=='safe_type':\n",
    "            continue\n",
    "        line=[float(k) for k in line]\n",
    "        trainX.append(line[1:])\n",
    "        trainY.append(line[0])\n",
    "    trainX=np.array(trainX)[:,:]\n",
    "    meanX=np.mean(trainX)\n",
    "    trainX-=meanX\n",
    "    trainY=np.array(trainY).astype(int)\n",
    "    #trainY[trainY==0]=-1\n",
    "    print(trainX.shape,trainY.shape)\n",
    "    \n",
    "    for line in testfile:\n",
    "        line=line.split(',')[1:]\n",
    "        if line[0]=='safe_type':\n",
    "            continue\n",
    "        line=[float(k) for k in line]\n",
    "        testX.append(line[1:])\n",
    "        testY.append(line[0])\n",
    "    testX=np.array(testX)[:,:]\n",
    "    testX-=meanX\n",
    "    testY=np.array(testY).astype(int)\n",
    "    #testY[testY==0]=-1\n",
    "    print(testX.shape,testY.shape)\n",
    "    input_shape=(trainX.shape[1],)\n",
    "    net = Network(input_shape, num_classes, trainX, trainY, testX, testY)\n",
    "    #print(net.model.summary())\n",
    "    net.fit(batch_size,epoch,verbose=1)\n",
    "    print(net.model.evaluate(testX,texsY))\n",
    "#     err=np.sum(testY[:,0]*ans<=0)/testY.shape[0]\n",
    "#     print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((24000, 5), (24000, 1))\n",
      "((6000, 5), (6000, 1))\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/300\n",
      "24000/24000 [==============================] - 3s 127us/step - loss: 0.1447 - acc: 0.8177 - val_loss: 0.1244 - val_acc: 0.8467\n",
      "Epoch 2/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.1280 - acc: 0.8379 - val_loss: 0.1235 - val_acc: 0.8460\n",
      "Epoch 3/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.1200 - acc: 0.8491 - val_loss: 0.1154 - val_acc: 0.8597\n",
      "Epoch 4/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.1142 - acc: 0.8543 - val_loss: 0.1233 - val_acc: 0.8425\n",
      "Epoch 5/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.1082 - acc: 0.8592 - val_loss: 0.1094 - val_acc: 0.8752\n",
      "Epoch 6/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.1028 - acc: 0.8693 - val_loss: 0.0993 - val_acc: 0.8743\n",
      "Epoch 7/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0962 - acc: 0.8786 - val_loss: 0.0992 - val_acc: 0.8628\n",
      "Epoch 8/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0920 - acc: 0.8822 - val_loss: 0.0893 - val_acc: 0.8845\n",
      "Epoch 9/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0894 - acc: 0.8845 - val_loss: 0.0862 - val_acc: 0.8890\n",
      "Epoch 10/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0852 - acc: 0.8884 - val_loss: 0.0931 - val_acc: 0.8837\n",
      "Epoch 11/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0845 - acc: 0.8893 - val_loss: 0.0969 - val_acc: 0.8825\n",
      "Epoch 12/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0814 - acc: 0.8920 - val_loss: 0.0799 - val_acc: 0.8975\n",
      "Epoch 13/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0803 - acc: 0.8957 - val_loss: 0.0763 - val_acc: 0.9073\n",
      "Epoch 14/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0799 - acc: 0.8962 - val_loss: 0.0796 - val_acc: 0.8950\n",
      "Epoch 15/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0778 - acc: 0.9000 - val_loss: 0.0790 - val_acc: 0.8950\n",
      "Epoch 16/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0774 - acc: 0.8997 - val_loss: 0.0825 - val_acc: 0.8918\n",
      "Epoch 17/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0747 - acc: 0.9006 - val_loss: 0.0709 - val_acc: 0.9068\n",
      "Epoch 18/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0748 - acc: 0.9025 - val_loss: 0.0707 - val_acc: 0.9040\n",
      "Epoch 19/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0744 - acc: 0.9042 - val_loss: 0.0723 - val_acc: 0.9043\n",
      "Epoch 20/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0722 - acc: 0.9056 - val_loss: 0.0720 - val_acc: 0.9085\n",
      "Epoch 21/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0723 - acc: 0.9070 - val_loss: 0.0847 - val_acc: 0.8980\n",
      "Epoch 22/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0714 - acc: 0.9081 - val_loss: 0.0682 - val_acc: 0.9138\n",
      "Epoch 23/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0704 - acc: 0.9101 - val_loss: 0.0857 - val_acc: 0.8897\n",
      "Epoch 24/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0697 - acc: 0.9097 - val_loss: 0.0714 - val_acc: 0.9093\n",
      "Epoch 25/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0707 - acc: 0.9081 - val_loss: 0.0676 - val_acc: 0.9127\n",
      "Epoch 26/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0691 - acc: 0.9110 - val_loss: 0.0853 - val_acc: 0.8930\n",
      "Epoch 27/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0696 - acc: 0.9094 - val_loss: 0.0798 - val_acc: 0.8927\n",
      "Epoch 28/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0699 - acc: 0.9097 - val_loss: 0.0731 - val_acc: 0.9118\n",
      "Epoch 29/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0684 - acc: 0.9113 - val_loss: 0.0674 - val_acc: 0.9100\n",
      "Epoch 30/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0692 - acc: 0.9078 - val_loss: 0.0642 - val_acc: 0.9185\n",
      "Epoch 31/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0666 - acc: 0.9129 - val_loss: 0.0702 - val_acc: 0.9075\n",
      "Epoch 32/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0677 - acc: 0.9126 - val_loss: 0.0679 - val_acc: 0.9077\n",
      "Epoch 33/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0667 - acc: 0.9118 - val_loss: 0.0967 - val_acc: 0.8740\n",
      "Epoch 34/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0672 - acc: 0.9121 - val_loss: 0.0663 - val_acc: 0.9153\n",
      "Epoch 35/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0664 - acc: 0.9131 - val_loss: 0.0691 - val_acc: 0.9085\n",
      "Epoch 36/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0646 - acc: 0.9148 - val_loss: 0.0729 - val_acc: 0.9052\n",
      "Epoch 37/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0666 - acc: 0.9123 - val_loss: 0.0708 - val_acc: 0.9013\n",
      "Epoch 38/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0651 - acc: 0.9164 - val_loss: 0.0703 - val_acc: 0.9095\n",
      "Epoch 39/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0656 - acc: 0.9141 - val_loss: 0.0670 - val_acc: 0.9157\n",
      "Epoch 40/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0650 - acc: 0.9149 - val_loss: 0.0618 - val_acc: 0.9190\n",
      "Epoch 41/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0655 - acc: 0.9137 - val_loss: 0.0616 - val_acc: 0.9177\n",
      "Epoch 42/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0632 - acc: 0.9180 - val_loss: 0.0683 - val_acc: 0.9162\n",
      "Epoch 43/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0641 - acc: 0.9160 - val_loss: 0.0641 - val_acc: 0.9190\n",
      "Epoch 44/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0649 - acc: 0.9149 - val_loss: 0.0632 - val_acc: 0.9200\n",
      "Epoch 45/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0636 - acc: 0.9165 - val_loss: 0.0657 - val_acc: 0.9157\n",
      "Epoch 46/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0628 - acc: 0.9177 - val_loss: 0.0607 - val_acc: 0.9175\n",
      "Epoch 47/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0628 - acc: 0.9180 - val_loss: 0.0612 - val_acc: 0.9213\n",
      "Epoch 48/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0627 - acc: 0.9180 - val_loss: 0.0626 - val_acc: 0.9242\n",
      "Epoch 49/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0628 - acc: 0.9173 - val_loss: 0.0635 - val_acc: 0.9198\n",
      "Epoch 50/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0624 - acc: 0.9179 - val_loss: 0.0635 - val_acc: 0.9245\n",
      "Epoch 51/300\n",
      "24000/24000 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.919 - 1s 26us/step - loss: 0.0617 - acc: 0.9196 - val_loss: 0.0644 - val_acc: 0.9180\n",
      "Epoch 52/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0614 - acc: 0.9199 - val_loss: 0.0692 - val_acc: 0.9143\n",
      "Epoch 53/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0615 - acc: 0.9195 - val_loss: 0.0611 - val_acc: 0.9223\n",
      "Epoch 54/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0621 - acc: 0.9203 - val_loss: 0.0719 - val_acc: 0.9132\n",
      "Epoch 55/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0602 - acc: 0.9216 - val_loss: 0.0694 - val_acc: 0.9133\n",
      "Epoch 56/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0611 - acc: 0.9210 - val_loss: 0.0633 - val_acc: 0.9147\n",
      "Epoch 57/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0611 - acc: 0.9194 - val_loss: 0.0608 - val_acc: 0.9210\n",
      "Epoch 58/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0608 - acc: 0.9215 - val_loss: 0.0670 - val_acc: 0.9173\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0600 - acc: 0.9228 - val_loss: 0.0606 - val_acc: 0.9252\n",
      "Epoch 60/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0601 - acc: 0.9222 - val_loss: 0.0619 - val_acc: 0.9195\n",
      "Epoch 61/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0598 - acc: 0.9205 - val_loss: 0.0671 - val_acc: 0.9165\n",
      "Epoch 62/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0605 - acc: 0.9219 - val_loss: 0.0591 - val_acc: 0.9243\n",
      "Epoch 63/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0597 - acc: 0.9212 - val_loss: 0.0646 - val_acc: 0.9160\n",
      "Epoch 64/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0585 - acc: 0.9243 - val_loss: 0.0645 - val_acc: 0.9170\n",
      "Epoch 65/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0593 - acc: 0.9228 - val_loss: 0.0643 - val_acc: 0.9152\n",
      "Epoch 66/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0596 - acc: 0.9223 - val_loss: 0.0592 - val_acc: 0.9230\n",
      "Epoch 67/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0594 - acc: 0.9228 - val_loss: 0.0667 - val_acc: 0.9150\n",
      "Epoch 68/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0589 - acc: 0.9246 - val_loss: 0.0712 - val_acc: 0.9163\n",
      "Epoch 69/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0586 - acc: 0.9249 - val_loss: 0.0651 - val_acc: 0.9182\n",
      "Epoch 70/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0599 - acc: 0.9228 - val_loss: 0.0576 - val_acc: 0.9248\n",
      "Epoch 71/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0589 - acc: 0.9248 - val_loss: 0.0706 - val_acc: 0.9067\n",
      "Epoch 72/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0586 - acc: 0.9236 - val_loss: 0.0627 - val_acc: 0.9188\n",
      "Epoch 73/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0583 - acc: 0.9245 - val_loss: 0.0571 - val_acc: 0.9285\n",
      "Epoch 74/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0575 - acc: 0.9255 - val_loss: 0.0619 - val_acc: 0.9225\n",
      "Epoch 75/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0577 - acc: 0.9250 - val_loss: 0.0586 - val_acc: 0.9225\n",
      "Epoch 76/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0580 - acc: 0.9230 - val_loss: 0.0644 - val_acc: 0.9228\n",
      "Epoch 77/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0576 - acc: 0.9251 - val_loss: 0.0575 - val_acc: 0.9228\n",
      "Epoch 78/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0574 - acc: 0.9253 - val_loss: 0.0553 - val_acc: 0.9268\n",
      "Epoch 79/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0572 - acc: 0.9238 - val_loss: 0.0558 - val_acc: 0.9292\n",
      "Epoch 80/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0567 - acc: 0.9269 - val_loss: 0.0691 - val_acc: 0.9152\n",
      "Epoch 81/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0566 - acc: 0.9261 - val_loss: 0.0563 - val_acc: 0.9300\n",
      "Epoch 82/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0569 - acc: 0.9253 - val_loss: 0.0603 - val_acc: 0.9188\n",
      "Epoch 83/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0569 - acc: 0.9252 - val_loss: 0.0555 - val_acc: 0.9228\n",
      "Epoch 84/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0557 - acc: 0.9267 - val_loss: 0.0569 - val_acc: 0.9222\n",
      "Epoch 85/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0563 - acc: 0.9265 - val_loss: 0.0528 - val_acc: 0.9310\n",
      "Epoch 86/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0558 - acc: 0.9270 - val_loss: 0.0547 - val_acc: 0.9273\n",
      "Epoch 87/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0563 - acc: 0.9264 - val_loss: 0.0532 - val_acc: 0.9323\n",
      "Epoch 88/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0557 - acc: 0.9272 - val_loss: 0.0535 - val_acc: 0.9297\n",
      "Epoch 89/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0563 - acc: 0.9268 - val_loss: 0.0529 - val_acc: 0.9343\n",
      "Epoch 90/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0551 - acc: 0.9284 - val_loss: 0.0675 - val_acc: 0.9122\n",
      "Epoch 91/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0555 - acc: 0.9276 - val_loss: 0.0679 - val_acc: 0.9072\n",
      "Epoch 92/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0560 - acc: 0.9276 - val_loss: 0.0694 - val_acc: 0.9117\n",
      "Epoch 93/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0558 - acc: 0.9274 - val_loss: 0.0644 - val_acc: 0.9162\n",
      "Epoch 94/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0560 - acc: 0.9270 - val_loss: 0.0679 - val_acc: 0.9143\n",
      "Epoch 95/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0542 - acc: 0.9283 - val_loss: 0.0557 - val_acc: 0.9283\n",
      "Epoch 96/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0550 - acc: 0.9282 - val_loss: 0.0562 - val_acc: 0.9260\n",
      "Epoch 97/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0546 - acc: 0.9287 - val_loss: 0.0577 - val_acc: 0.9287\n",
      "Epoch 98/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0554 - acc: 0.9268 - val_loss: 0.0605 - val_acc: 0.9188\n",
      "Epoch 99/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0541 - acc: 0.9291 - val_loss: 0.0742 - val_acc: 0.9007\n",
      "Epoch 100/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0546 - acc: 0.9291 - val_loss: 0.0772 - val_acc: 0.8993\n",
      "Epoch 101/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0546 - acc: 0.9283 - val_loss: 0.0527 - val_acc: 0.9303\n",
      "Epoch 102/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0543 - acc: 0.9280 - val_loss: 0.0607 - val_acc: 0.9237\n",
      "Epoch 103/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0546 - acc: 0.9280 - val_loss: 0.0577 - val_acc: 0.9230\n",
      "Epoch 104/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0541 - acc: 0.9287 - val_loss: 0.0560 - val_acc: 0.9240\n",
      "Epoch 105/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0542 - acc: 0.9289 - val_loss: 0.0541 - val_acc: 0.9293\n",
      "Epoch 106/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0540 - acc: 0.9294 - val_loss: 0.0556 - val_acc: 0.9280\n",
      "Epoch 107/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0545 - acc: 0.9290 - val_loss: 0.0603 - val_acc: 0.9233\n",
      "Epoch 108/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0540 - acc: 0.9296 - val_loss: 0.0573 - val_acc: 0.9287\n",
      "Epoch 109/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0537 - acc: 0.9308 - val_loss: 0.0666 - val_acc: 0.9132\n",
      "Epoch 110/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0537 - acc: 0.9293 - val_loss: 0.0552 - val_acc: 0.9293\n",
      "Epoch 111/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0535 - acc: 0.9301 - val_loss: 0.0520 - val_acc: 0.9307\n",
      "Epoch 112/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0533 - acc: 0.9303 - val_loss: 0.0548 - val_acc: 0.9285\n",
      "Epoch 113/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0533 - acc: 0.9284 - val_loss: 0.0563 - val_acc: 0.9260\n",
      "Epoch 114/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0533 - acc: 0.9293 - val_loss: 0.0659 - val_acc: 0.9123\n",
      "Epoch 115/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0542 - acc: 0.9288 - val_loss: 0.0634 - val_acc: 0.9200\n",
      "Epoch 116/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0533 - acc: 0.9286 - val_loss: 0.0529 - val_acc: 0.9305\n",
      "Epoch 117/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0530 - acc: 0.9300 - val_loss: 0.0518 - val_acc: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0532 - acc: 0.9303 - val_loss: 0.0520 - val_acc: 0.9333\n",
      "Epoch 119/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0539 - acc: 0.9293 - val_loss: 0.0519 - val_acc: 0.9277\n",
      "Epoch 120/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0527 - acc: 0.9306 - val_loss: 0.0669 - val_acc: 0.9208\n",
      "Epoch 121/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0535 - acc: 0.9300 - val_loss: 0.0600 - val_acc: 0.9212\n",
      "Epoch 122/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0529 - acc: 0.9298 - val_loss: 0.0516 - val_acc: 0.9297\n",
      "Epoch 123/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0527 - acc: 0.9306 - val_loss: 0.0586 - val_acc: 0.9238\n",
      "Epoch 124/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0523 - acc: 0.9310 - val_loss: 0.0622 - val_acc: 0.9178\n",
      "Epoch 125/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0525 - acc: 0.9311 - val_loss: 0.0534 - val_acc: 0.9298\n",
      "Epoch 126/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0528 - acc: 0.9311 - val_loss: 0.0531 - val_acc: 0.9293\n",
      "Epoch 127/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0528 - acc: 0.9301 - val_loss: 0.0554 - val_acc: 0.9277\n",
      "Epoch 128/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0528 - acc: 0.9311 - val_loss: 0.0507 - val_acc: 0.9332\n",
      "Epoch 129/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0520 - acc: 0.9311 - val_loss: 0.0527 - val_acc: 0.9305\n",
      "Epoch 130/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0520 - acc: 0.9317 - val_loss: 0.0515 - val_acc: 0.9343\n",
      "Epoch 131/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0523 - acc: 0.9303 - val_loss: 0.0521 - val_acc: 0.9328\n",
      "Epoch 132/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0532 - acc: 0.9304 - val_loss: 0.0533 - val_acc: 0.9290\n",
      "Epoch 133/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0510 - acc: 0.9336 - val_loss: 0.0537 - val_acc: 0.9287\n",
      "Epoch 134/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0524 - acc: 0.9320 - val_loss: 0.0514 - val_acc: 0.9315\n",
      "Epoch 135/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0525 - acc: 0.9313 - val_loss: 0.0508 - val_acc: 0.9327\n",
      "Epoch 136/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0520 - acc: 0.9320 - val_loss: 0.0569 - val_acc: 0.9263\n",
      "Epoch 137/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9333 - val_loss: 0.0556 - val_acc: 0.9272\n",
      "Epoch 138/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0515 - acc: 0.9327 - val_loss: 0.0544 - val_acc: 0.9310\n",
      "Epoch 139/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0523 - acc: 0.9304 - val_loss: 0.0490 - val_acc: 0.9347\n",
      "Epoch 140/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9319 - val_loss: 0.0561 - val_acc: 0.9273\n",
      "Epoch 141/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0518 - acc: 0.9323 - val_loss: 0.0569 - val_acc: 0.9242\n",
      "Epoch 142/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9319 - val_loss: 0.0550 - val_acc: 0.9277\n",
      "Epoch 143/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9320 - val_loss: 0.0509 - val_acc: 0.9327\n",
      "Epoch 144/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9338 - val_loss: 0.0610 - val_acc: 0.9220\n",
      "Epoch 145/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0511 - acc: 0.9336 - val_loss: 0.0605 - val_acc: 0.9203\n",
      "Epoch 146/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0523 - acc: 0.9319 - val_loss: 0.0507 - val_acc: 0.9302\n",
      "Epoch 147/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0516 - acc: 0.9322 - val_loss: 0.0568 - val_acc: 0.9245\n",
      "Epoch 148/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0517 - acc: 0.9323 - val_loss: 0.0528 - val_acc: 0.9323\n",
      "Epoch 149/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0512 - acc: 0.9330 - val_loss: 0.0511 - val_acc: 0.9313\n",
      "Epoch 150/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9328 - val_loss: 0.0537 - val_acc: 0.9293\n",
      "Epoch 151/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0516 - acc: 0.9322 - val_loss: 0.0600 - val_acc: 0.9255\n",
      "Epoch 152/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0507 - acc: 0.9330 - val_loss: 0.0518 - val_acc: 0.9333\n",
      "Epoch 153/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0515 - acc: 0.9307 - val_loss: 0.0534 - val_acc: 0.9290\n",
      "Epoch 154/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0514 - acc: 0.9324 - val_loss: 0.0554 - val_acc: 0.9317\n",
      "Epoch 155/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0508 - acc: 0.9332 - val_loss: 0.0644 - val_acc: 0.9208\n",
      "Epoch 156/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0504 - acc: 0.9344 - val_loss: 0.0551 - val_acc: 0.9338\n",
      "Epoch 157/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0505 - acc: 0.9337 - val_loss: 0.0521 - val_acc: 0.9307\n",
      "Epoch 158/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0510 - acc: 0.9337 - val_loss: 0.0568 - val_acc: 0.9263\n",
      "Epoch 159/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0512 - acc: 0.9325 - val_loss: 0.0550 - val_acc: 0.9290\n",
      "Epoch 160/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9332 - val_loss: 0.0504 - val_acc: 0.9323\n",
      "Epoch 161/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0510 - acc: 0.9319 - val_loss: 0.0551 - val_acc: 0.9245\n",
      "Epoch 162/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0506 - acc: 0.9345 - val_loss: 0.0500 - val_acc: 0.9355\n",
      "Epoch 163/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0507 - acc: 0.9333 - val_loss: 0.0617 - val_acc: 0.9248\n",
      "Epoch 164/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0510 - acc: 0.9324 - val_loss: 0.0497 - val_acc: 0.9362\n",
      "Epoch 165/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0502 - acc: 0.9345 - val_loss: 0.0518 - val_acc: 0.9310\n",
      "Epoch 166/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0514 - acc: 0.9327 - val_loss: 0.0611 - val_acc: 0.9300\n",
      "Epoch 167/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0505 - acc: 0.9325 - val_loss: 0.0525 - val_acc: 0.9312\n",
      "Epoch 168/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0512 - acc: 0.9324 - val_loss: 0.0532 - val_acc: 0.9322\n",
      "Epoch 169/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0501 - acc: 0.9342 - val_loss: 0.0639 - val_acc: 0.9107\n",
      "Epoch 170/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0512 - acc: 0.9338 - val_loss: 0.0525 - val_acc: 0.9313\n",
      "Epoch 171/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0497 - acc: 0.9347 - val_loss: 0.0527 - val_acc: 0.9330\n",
      "Epoch 172/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0503 - acc: 0.9345 - val_loss: 0.0499 - val_acc: 0.9355\n",
      "Epoch 173/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0509 - acc: 0.9326 - val_loss: 0.0495 - val_acc: 0.9347\n",
      "Epoch 174/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0501 - acc: 0.9343 - val_loss: 0.0516 - val_acc: 0.9317\n",
      "Epoch 175/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0505 - acc: 0.9335 - val_loss: 0.0511 - val_acc: 0.9335\n",
      "Epoch 176/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0504 - acc: 0.9341 - val_loss: 0.0596 - val_acc: 0.9238\n",
      "Epoch 177/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0507 - acc: 0.9319 - val_loss: 0.0493 - val_acc: 0.9348\n",
      "Epoch 178/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0505 - acc: 0.9343 - val_loss: 0.0513 - val_acc: 0.9315\n",
      "Epoch 179/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0504 - acc: 0.9340 - val_loss: 0.0508 - val_acc: 0.9333\n",
      "Epoch 180/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0507 - acc: 0.9332 - val_loss: 0.0530 - val_acc: 0.9307\n",
      "Epoch 181/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0504 - acc: 0.9330 - val_loss: 0.0528 - val_acc: 0.9322\n",
      "Epoch 182/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0497 - acc: 0.9347 - val_loss: 0.0517 - val_acc: 0.9335\n",
      "Epoch 183/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0499 - acc: 0.9345 - val_loss: 0.0527 - val_acc: 0.9283\n",
      "Epoch 184/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0496 - acc: 0.9352 - val_loss: 0.0555 - val_acc: 0.9302\n",
      "Epoch 185/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0499 - acc: 0.9338 - val_loss: 0.0507 - val_acc: 0.9337\n",
      "Epoch 186/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0503 - acc: 0.9327 - val_loss: 0.0607 - val_acc: 0.9237\n",
      "Epoch 187/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0500 - acc: 0.9344 - val_loss: 0.0503 - val_acc: 0.9367\n",
      "Epoch 188/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0507 - acc: 0.9340 - val_loss: 0.0498 - val_acc: 0.9385\n",
      "Epoch 189/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0497 - acc: 0.9345 - val_loss: 0.0573 - val_acc: 0.9225\n",
      "Epoch 190/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0496 - acc: 0.9355 - val_loss: 0.0500 - val_acc: 0.9338\n",
      "Epoch 191/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0502 - acc: 0.9340 - val_loss: 0.0493 - val_acc: 0.9347\n",
      "Epoch 192/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0496 - acc: 0.9341 - val_loss: 0.0502 - val_acc: 0.9337\n",
      "Epoch 193/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0503 - acc: 0.9340 - val_loss: 0.0529 - val_acc: 0.9327\n",
      "Epoch 194/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0492 - acc: 0.9356 - val_loss: 0.0506 - val_acc: 0.9377\n",
      "Epoch 195/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0494 - acc: 0.9361 - val_loss: 0.0502 - val_acc: 0.9373\n",
      "Epoch 196/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0495 - acc: 0.9357 - val_loss: 0.0544 - val_acc: 0.9277\n",
      "Epoch 197/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0490 - acc: 0.9357 - val_loss: 0.0503 - val_acc: 0.9342\n",
      "Epoch 198/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0497 - acc: 0.9350 - val_loss: 0.0537 - val_acc: 0.9327\n",
      "Epoch 199/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0496 - acc: 0.9346 - val_loss: 0.0519 - val_acc: 0.9328\n",
      "Epoch 200/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0491 - acc: 0.9360 - val_loss: 0.0484 - val_acc: 0.9380\n",
      "Epoch 201/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0494 - acc: 0.9348 - val_loss: 0.0592 - val_acc: 0.9272\n",
      "Epoch 202/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0498 - acc: 0.9350 - val_loss: 0.0507 - val_acc: 0.9338\n",
      "Epoch 203/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0493 - acc: 0.9366 - val_loss: 0.0548 - val_acc: 0.9283\n",
      "Epoch 204/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0493 - acc: 0.9353 - val_loss: 0.0673 - val_acc: 0.9190\n",
      "Epoch 205/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0501 - acc: 0.9346 - val_loss: 0.0526 - val_acc: 0.9325\n",
      "Epoch 206/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0493 - acc: 0.9345 - val_loss: 0.0482 - val_acc: 0.9368\n",
      "Epoch 207/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0489 - acc: 0.9367 - val_loss: 0.0498 - val_acc: 0.9342\n",
      "Epoch 208/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0493 - acc: 0.9358 - val_loss: 0.0517 - val_acc: 0.9298\n",
      "Epoch 209/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0491 - acc: 0.9361 - val_loss: 0.0499 - val_acc: 0.9390\n",
      "Epoch 210/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0487 - acc: 0.9365 - val_loss: 0.0564 - val_acc: 0.9268\n",
      "Epoch 211/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0500 - acc: 0.9345 - val_loss: 0.0536 - val_acc: 0.9305\n",
      "Epoch 212/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0485 - acc: 0.9362 - val_loss: 0.0515 - val_acc: 0.9372\n",
      "Epoch 213/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0489 - acc: 0.9358 - val_loss: 0.0485 - val_acc: 0.9380\n",
      "Epoch 214/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0491 - acc: 0.9356 - val_loss: 0.0494 - val_acc: 0.9393\n",
      "Epoch 215/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0503 - acc: 0.9357 - val_loss: 0.0474 - val_acc: 0.9368\n",
      "Epoch 216/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0490 - acc: 0.9356 - val_loss: 0.0583 - val_acc: 0.9237\n",
      "Epoch 217/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9366 - val_loss: 0.0523 - val_acc: 0.9337\n",
      "Epoch 218/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0486 - acc: 0.9360 - val_loss: 0.0574 - val_acc: 0.9285\n",
      "Epoch 219/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0494 - acc: 0.9342 - val_loss: 0.0485 - val_acc: 0.9370\n",
      "Epoch 220/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0486 - acc: 0.9362 - val_loss: 0.0538 - val_acc: 0.9287\n",
      "Epoch 221/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9352 - val_loss: 0.0591 - val_acc: 0.9257\n",
      "Epoch 222/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0497 - acc: 0.9362 - val_loss: 0.0613 - val_acc: 0.9247\n",
      "Epoch 223/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0486 - acc: 0.9371 - val_loss: 0.0517 - val_acc: 0.9305\n",
      "Epoch 224/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9366 - val_loss: 0.0656 - val_acc: 0.9162\n",
      "Epoch 225/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0485 - acc: 0.9375 - val_loss: 0.0502 - val_acc: 0.9308\n",
      "Epoch 226/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0490 - acc: 0.9364 - val_loss: 0.0488 - val_acc: 0.9380\n",
      "Epoch 227/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0489 - acc: 0.9365 - val_loss: 0.0467 - val_acc: 0.9388\n",
      "Epoch 228/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0487 - acc: 0.9364 - val_loss: 0.0539 - val_acc: 0.9242\n",
      "Epoch 229/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0489 - acc: 0.9368 - val_loss: 0.0485 - val_acc: 0.9360\n",
      "Epoch 230/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0479 - acc: 0.9364 - val_loss: 0.0528 - val_acc: 0.9328\n",
      "Epoch 231/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0490 - acc: 0.9368 - val_loss: 0.0469 - val_acc: 0.9392\n",
      "Epoch 232/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9361 - val_loss: 0.0507 - val_acc: 0.9325\n",
      "Epoch 233/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0478 - acc: 0.9365 - val_loss: 0.0483 - val_acc: 0.9390\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0485 - acc: 0.9369 - val_loss: 0.0504 - val_acc: 0.9357\n",
      "Epoch 235/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9361 - val_loss: 0.0583 - val_acc: 0.9222\n",
      "Epoch 236/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0485 - acc: 0.9361 - val_loss: 0.0588 - val_acc: 0.9298\n",
      "Epoch 237/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0485 - acc: 0.9351 - val_loss: 0.0541 - val_acc: 0.9297\n",
      "Epoch 238/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0485 - acc: 0.9365 - val_loss: 0.0534 - val_acc: 0.9308\n",
      "Epoch 239/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0486 - acc: 0.9362 - val_loss: 0.0508 - val_acc: 0.9337\n",
      "Epoch 240/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9378 - val_loss: 0.0574 - val_acc: 0.9265\n",
      "Epoch 241/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0488 - acc: 0.9359 - val_loss: 0.0492 - val_acc: 0.9372\n",
      "Epoch 242/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9355 - val_loss: 0.0475 - val_acc: 0.9395\n",
      "Epoch 243/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9364 - val_loss: 0.0508 - val_acc: 0.9328\n",
      "Epoch 244/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0491 - acc: 0.9357 - val_loss: 0.0487 - val_acc: 0.9395\n",
      "Epoch 245/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0472 - acc: 0.9373 - val_loss: 0.0540 - val_acc: 0.9282\n",
      "Epoch 246/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0482 - acc: 0.9362 - val_loss: 0.0542 - val_acc: 0.9302\n",
      "Epoch 247/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0483 - acc: 0.9363 - val_loss: 0.0504 - val_acc: 0.9357\n",
      "Epoch 248/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0496 - acc: 0.9350 - val_loss: 0.0482 - val_acc: 0.9355\n",
      "Epoch 249/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9374 - val_loss: 0.0509 - val_acc: 0.9317\n",
      "Epoch 250/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9366 - val_loss: 0.0480 - val_acc: 0.9370\n",
      "Epoch 251/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0484 - acc: 0.9371 - val_loss: 0.0493 - val_acc: 0.9373\n",
      "Epoch 252/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0484 - acc: 0.9364 - val_loss: 0.0532 - val_acc: 0.9308\n",
      "Epoch 253/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0483 - acc: 0.9371 - val_loss: 0.0601 - val_acc: 0.9198\n",
      "Epoch 254/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0481 - acc: 0.9367 - val_loss: 0.0485 - val_acc: 0.9380\n",
      "Epoch 255/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0479 - acc: 0.9376 - val_loss: 0.0501 - val_acc: 0.9370\n",
      "Epoch 256/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0484 - acc: 0.9375 - val_loss: 0.0489 - val_acc: 0.9352\n",
      "Epoch 257/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0484 - acc: 0.9380 - val_loss: 0.0488 - val_acc: 0.9395\n",
      "Epoch 258/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0479 - acc: 0.9374 - val_loss: 0.0500 - val_acc: 0.9355\n",
      "Epoch 259/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9380 - val_loss: 0.0537 - val_acc: 0.9307\n",
      "Epoch 260/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0470 - acc: 0.9391 - val_loss: 0.0538 - val_acc: 0.9282\n",
      "Epoch 261/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9368 - val_loss: 0.0460 - val_acc: 0.9417\n",
      "Epoch 262/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0474 - acc: 0.9385 - val_loss: 0.0510 - val_acc: 0.9363\n",
      "Epoch 263/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9376 - val_loss: 0.0512 - val_acc: 0.9352\n",
      "Epoch 264/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0473 - acc: 0.9391 - val_loss: 0.0486 - val_acc: 0.9397\n",
      "Epoch 265/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0489 - acc: 0.9382 - val_loss: 0.0547 - val_acc: 0.9263\n",
      "Epoch 266/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0483 - acc: 0.9372 - val_loss: 0.0513 - val_acc: 0.9348\n",
      "Epoch 267/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0477 - acc: 0.9387 - val_loss: 0.0479 - val_acc: 0.9397\n",
      "Epoch 268/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0472 - acc: 0.9394 - val_loss: 0.0553 - val_acc: 0.9290\n",
      "Epoch 269/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0472 - acc: 0.9385 - val_loss: 0.0476 - val_acc: 0.9378\n",
      "Epoch 270/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0474 - acc: 0.9365 - val_loss: 0.0542 - val_acc: 0.9347\n",
      "Epoch 271/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0473 - acc: 0.9380 - val_loss: 0.0505 - val_acc: 0.9347\n",
      "Epoch 272/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9370 - val_loss: 0.0450 - val_acc: 0.9433\n",
      "Epoch 273/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9367 - val_loss: 0.0483 - val_acc: 0.9380\n",
      "Epoch 274/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0473 - acc: 0.9373 - val_loss: 0.0525 - val_acc: 0.9350\n",
      "Epoch 275/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0482 - acc: 0.9382 - val_loss: 0.0505 - val_acc: 0.9380\n",
      "Epoch 276/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0481 - acc: 0.9373 - val_loss: 0.0495 - val_acc: 0.9357\n",
      "Epoch 277/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0490 - acc: 0.9376 - val_loss: 0.0468 - val_acc: 0.9382\n",
      "Epoch 278/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0465 - acc: 0.9397 - val_loss: 0.0477 - val_acc: 0.9383\n",
      "Epoch 279/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0470 - acc: 0.9395 - val_loss: 0.0492 - val_acc: 0.9352\n",
      "Epoch 280/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0475 - acc: 0.9380 - val_loss: 0.0499 - val_acc: 0.9347\n",
      "Epoch 281/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0473 - acc: 0.9388 - val_loss: 0.0506 - val_acc: 0.9343\n",
      "Epoch 282/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0476 - acc: 0.9380 - val_loss: 0.0529 - val_acc: 0.9343\n",
      "Epoch 283/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0473 - acc: 0.9391 - val_loss: 0.0492 - val_acc: 0.9370\n",
      "Epoch 284/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0473 - acc: 0.9383 - val_loss: 0.0477 - val_acc: 0.9387\n",
      "Epoch 285/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9362 - val_loss: 0.0528 - val_acc: 0.9285\n",
      "Epoch 286/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0483 - acc: 0.9368 - val_loss: 0.0500 - val_acc: 0.9332\n",
      "Epoch 287/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9397 - val_loss: 0.0483 - val_acc: 0.9380\n",
      "Epoch 288/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0472 - acc: 0.9382 - val_loss: 0.0523 - val_acc: 0.9298\n",
      "Epoch 289/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0482 - acc: 0.9372 - val_loss: 0.0484 - val_acc: 0.9383\n",
      "Epoch 290/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0467 - acc: 0.9389 - val_loss: 0.0520 - val_acc: 0.9333\n",
      "Epoch 291/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0473 - acc: 0.9381 - val_loss: 0.0491 - val_acc: 0.9360\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0479 - acc: 0.9376 - val_loss: 0.0448 - val_acc: 0.9455\n",
      "Epoch 293/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0471 - acc: 0.9386 - val_loss: 0.0498 - val_acc: 0.9357\n",
      "Epoch 294/300\n",
      "24000/24000 [==============================] - 1s 25us/step - loss: 0.0473 - acc: 0.9402 - val_loss: 0.0458 - val_acc: 0.9410\n",
      "Epoch 295/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0470 - acc: 0.9383 - val_loss: 0.0563 - val_acc: 0.9285\n",
      "Epoch 296/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0475 - acc: 0.9397 - val_loss: 0.0480 - val_acc: 0.9400\n",
      "Epoch 297/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0471 - acc: 0.9387 - val_loss: 0.0473 - val_acc: 0.9397\n",
      "Epoch 298/300\n",
      "24000/24000 [==============================] - 1s 27us/step - loss: 0.0473 - acc: 0.9390 - val_loss: 0.0508 - val_acc: 0.9350\n",
      "Epoch 299/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0470 - acc: 0.9389 - val_loss: 0.0502 - val_acc: 0.9350\n",
      "Epoch 300/300\n",
      "24000/24000 [==============================] - 1s 26us/step - loss: 0.0478 - acc: 0.9365 - val_loss: 0.0471 - val_acc: 0.9405\n",
      "6000/6000 [==============================] - 0s 33us/step\n",
      "[0.047069171742225684, 0.9405]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " ...\n",
      " [0.8965442 ]\n",
      " [0.9037885 ]\n",
      " [0.89437157]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size=128\n",
    "epoch=300\n",
    "trainfile=open('{0}/full/train_features_full.csv'.format(datapath,flod,flod+1))\n",
    "testfile=open('{0}/full/test_features_full.csv'.format(datapath,flod,flod+1))\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "testX=[]\n",
    "testY=[]\n",
    "for line in trainfile:\n",
    "    line=line.split(',')[1:]\n",
    "    if line[0]=='safe_type':\n",
    "        continue\n",
    "    line=[float(k) for k in line]\n",
    "    trainX.append(line[1:])\n",
    "    trainY.append(line[0])\n",
    "trainX=np.array(trainX)[:,:5]\n",
    "trainY=np.array(trainY)[:,np.newaxis].astype(int)\n",
    "print(trainX.shape,trainY.shape)\n",
    "\n",
    "for line in testfile:\n",
    "    line=line.split(',')[1:]\n",
    "    if line[0]=='safe_type':\n",
    "        continue\n",
    "    line=[float(k) for k in line]\n",
    "    testX.append(line[1:])\n",
    "    testY.append(line[0])\n",
    "testX=np.array(testX)[:,:5]\n",
    "testY=np.array(testY)[:,np.newaxis].astype(int)\n",
    "print(testX.shape,testY.shape)\n",
    "\n",
    "input_shape=(trainX.shape[1],)\n",
    "net = Network(input_shape, num_classes, trainX, trainY, testX, testY)\n",
    "\n",
    "\n",
    "net.fit(batch_size,epoch,verbose=1,callbacks=[History()])\n",
    "print(net.model.evaluate(testX,testY))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdf359899d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_acc=np.load('../result/train_acc.npy')\n",
    "train_loss=np.load('../result/train_loss.npy')\n",
    "test_acc=np.load('../result/test_acc.npy')\n",
    "test_loss=np.load('../result/test_loss.npy')\n",
    "plt.cla()\n",
    "plt.plot(train_acc,'r',linewidth=3)\n",
    "plt.plot(test_acc,'b',linewidth=3)\n",
    "plt.legend(['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1)\n"
     ]
    }
   ],
   "source": [
    "ans=net.model.predict(testX)\n",
    "print(ans.shape)\n",
    "ans=ans[:,0]\n",
    "ans[ans>=0.5]=1\n",
    "ans[ans<0.5]=0\n",
    "outfile=open('{0}/full/result_NN.csv'.format(datapath),'w')\n",
    "for i in range(0,testY.shape[0]):\n",
    "    outfile.write('{0},{1}\\n'.format(int(testY[i][0]),ans[i]))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922\n"
     ]
    }
   ],
   "source": [
    "infile=open('{0}/full/result_NN.csv'.format(datapath))\n",
    "count=0\n",
    "score=0\n",
    "for line in infile:\n",
    "    count+=1\n",
    "    line=line.replace('\\n','').split(',')\n",
    "    line=np.array([float(k) for k in line]).astype(int)\n",
    "    if line[0]==line[1]:\n",
    "        score+=1\n",
    "    score-=(line[1]-line[0])*line[1]\n",
    "print(float(score)/count)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
